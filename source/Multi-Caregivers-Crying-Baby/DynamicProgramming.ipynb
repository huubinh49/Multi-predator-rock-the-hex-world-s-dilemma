{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using GLPK\n",
    "using XLSX\n",
    "using Ipopt\n",
    "using D3Trees\n",
    "using BenchmarkTools\n",
    "import Base.Iterators: product\n",
    "import Random.shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ordered_observations (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SATED = 1\n",
    "HUNGRY = 2\n",
    "FEED = 1\n",
    "IGNORE = 2\n",
    "SING = 3\n",
    "CRYING = true\n",
    "QUIET = false\n",
    "r_hungry = -10.0\n",
    "r_feed = -5.0\n",
    "r_sing = -0.5\n",
    "p_become_hungry = 0.1\n",
    "p_cry_when_hungry = 0.8\n",
    "p_cry_when_not_hungry = 0.1\n",
    "p_cry_when_hungry_in_sing = 0.9\n",
    "discount_factor = 0.9\n",
    "n_agents = 2\n",
    "ordered_states() = [SATED, HUNGRY]\n",
    "ordered_actions(i::Int) = [FEED, IGNORE, SING]\n",
    "ordered_observations(i::Int) = [CRYING, QUIET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct POMG\n",
    "   γ # discount factor\n",
    "   ℐ # agents\n",
    "   𝒮 # state space\n",
    "   𝒜 # joint action space\n",
    "   𝒪 # joint observation space\n",
    "   T # transition function\n",
    "   O # joint observation function\n",
    "   R # joint reward function\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SimpleGame\n",
    "   γ # discount factor\n",
    "   ℐ # agents\n",
    "   𝒜 # joint action space\n",
    "   R # joint reward function\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NashEquilibrium \n",
    "end\n",
    "\n",
    "struct ConditionalPlan\n",
    "   a # action to take at root\n",
    "   subplans # dictionary mapping observations to subplans\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct POMGNashEquilibrium\n",
    "   b # initial belief\n",
    "   d # depth of conditional plans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transition (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function transition(s, a, s1)\n",
    "   # Regardless, feeding makes the baby sated.\n",
    "   if a[1] == FEED || a[2] == FEED\n",
    "       if s1 == SATED\n",
    "           return 1.0\n",
    "       else\n",
    "           return 0.0\n",
    "       end\n",
    "   else\n",
    "       # If neither caretaker fed, then one of two things happens.\n",
    "       # First, a baby that is hungry remains hungry.\n",
    "       if s == HUNGRY\n",
    "           if s1 == HUNGRY\n",
    "               return 1.0\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Otherwise, it becomes hungry with a fixed probability.\n",
    "       else\n",
    "           probBecomeHungry = 0.5 #pomg.babyPOMDP.p_become_hungry\n",
    "           if s1 == SATED\n",
    "               return 1.0 - probBecomeHungry\n",
    "           else\n",
    "               return probBecomeHungry\n",
    "           end\n",
    "       end\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_reward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function joint_reward(s, a)\n",
    "   r = [0.0, 0.0]\n",
    "\n",
    "   # Both caregivers do not want the child to be hungry.\n",
    "   if s == HUNGRY\n",
    "       r += [r_hungry, r_hungry]\n",
    "   end\n",
    "\n",
    "   # One caregiver prefers to feed.\n",
    "   if a[1] == FEED\n",
    "       r[1] += r_feed / 2.0\n",
    "   elseif a[1] == SING\n",
    "       r[1] += r_sing\n",
    "   end\n",
    "\n",
    "   # One caregiver prefers to sing.\n",
    "   if a[2] == FEED\n",
    "       r[2] += r_feed\n",
    "   elseif a[2] == SING\n",
    "       r[2] += r_sing / 2.0\n",
    "   end\n",
    "\n",
    "   # Note that caregivers only experience a cost if they do something.\n",
    "\n",
    "   return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Observation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_observation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function joint_observation(a, s1, o)\n",
    "   # If at least one caregiver sings, then both observe the result.\n",
    "   if a[1] == SING || a[2] == SING\n",
    "       # If the baby is hungry, then the caregivers both observe crying/silent together.\n",
    "       if s1 == HUNGRY\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_hungry_in_sing\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_hungry_in_sing\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Otherwise the baby is sated, and the baby is silent.\n",
    "       else\n",
    "           if o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       end\n",
    "   # Otherwise, the caregivers fed and/or ignored the baby.\n",
    "   else\n",
    "       # If the baby is hungry, then there's a probability it cries.\n",
    "       if s1 == HUNGRY\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_hungry\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_hungry\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Similarly when it is sated.\n",
    "       else\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_not_hungry\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_not_hungry\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       end\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize POMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POMG_Init (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function POMG_Init()\n",
    "   return POMG(\n",
    "       discount_factor,\n",
    "       vec(collect(1:n_agents)),\n",
    "       ordered_states(),\n",
    "       [ordered_actions(i) for i in 1:n_agents],\n",
    "       [ordered_observations(i) for i in 1:n_agents],\n",
    "       (s, a, s1) -> transition(s, a, s1),\n",
    "       (a, s1, o) -> joint_observation(a, s1, o),\n",
    "       (s, a) -> joint_reward(s, a)\n",
    "   )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Conditioinal Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConditionalPlan(a) = ConditionalPlan(a, Dict())\n",
    "(π::ConditionalPlan)() = π.a\n",
    "(π::ConditionalPlan)(o) = π.subplans[o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ConditionalPlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lookahead (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function lookahead(𝒫::POMG, U, s, a)\n",
    "   𝒮, 𝒪, T, O, R, γ = 𝒫.𝒮, joint(𝒫.𝒪), 𝒫.T, 𝒫.O, 𝒫.R, 𝒫.γ\n",
    "   u′ = sum(T(s,a,s′)*sum(O(a,s′,o)*U(o,s′) for o in 𝒪) for s′ in 𝒮)\n",
    "   return R(s,a) + γ*u′\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_plan (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function evaluate_plan(𝒫::POMG, π, s)\n",
    "   a = Tuple(πi() for πi in π)\n",
    "   U(o,s′) = evaluate_plan(𝒫, [πi(oi) for (πi, oi) in zip(π,o)], s′)\n",
    "   return isempty(first(π).subplans) ? 𝒫.R(s,a) : lookahead(𝒫, U, s, a)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utility (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function utility(𝒫::POMG, b, π)\n",
    "   u = [evaluate_plan(𝒫, π, s) for s in 𝒫.𝒮]\n",
    "   return sum(bs * us for (bs, us) in zip(b, u))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_conditional_plans (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_conditional_plans(𝒫, d)\n",
    "   ℐ, 𝒜, 𝒪 = 𝒫.ℐ, 𝒫.𝒜, 𝒫.𝒪\n",
    "   Π = [[ConditionalPlan(ai) for ai in 𝒜[i]] for i in ℐ]\n",
    "   for t in 1:d\n",
    "      Π = expand_conditional_plans(𝒫, Π)\n",
    "   end\n",
    "   return Π\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expand_conditional_plans (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function expand_conditional_plans(𝒫, Π)\n",
    "   ℐ, 𝒜, 𝒪 = 𝒫.ℐ, 𝒫.𝒜, 𝒫.𝒪\n",
    "   return [[ConditionalPlan(ai, Dict(oi => πi for oi in 𝒪[i])) for πi in Π[i] for ai in 𝒜[i]] for i in ℐ]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SimpleGamePolicy\n",
    "   p # dictionary mapping actions to probabilities\n",
    "   function SimpleGamePolicy(p::Base.Generator)\n",
    "       return SimpleGamePolicy(Dict(p))\n",
    "   end\n",
    "\n",
    "   function SimpleGamePolicy(p::Dict)\n",
    "       vs = collect(values(p))\n",
    "       vs ./= sum(vs)\n",
    "       return new(Dict(k => v for (k,v) in zip(keys(p), vs)))\n",
    "   end\n",
    "   SimpleGamePolicy(ai) = new(Dict(ai => 1.0))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(πi::SimpleGamePolicy)(ai) = get(πi.p, ai, 0.0)\n",
    "function (πi::SimpleGamePolicy)()\n",
    "   D = SetCategorical(collect(keys(πi.p)), collect(values(πi.p)))\n",
    "   return rand(D)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joint(X) = vec(collect(product(X...)))\n",
    "joint(π, πi, i) = [i == j ? πi : πj for (j, πj) in enumerate(π)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utility (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function utility(𝒫::SimpleGame, π, i)\n",
    "   𝒜, R = 𝒫.𝒜, 𝒫.R\n",
    "   p(a) = prod(πj(aj) for (πj, aj) in zip(π, a))\n",
    "   return sum(R(a)[i]*p(a) for a in joint(𝒜))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function solve(M::NashEquilibrium, 𝒫::SimpleGame)\n",
    "   ℐ, 𝒜, R = tensorform(𝒫)\n",
    "   model = Model(Ipopt.Optimizer)\n",
    "   @variable(model, U[ℐ])\n",
    "   @variable(model, π[i=ℐ, 𝒜[i]] ≥ 0)\n",
    "   @NLobjective(model, Min,\n",
    "       sum(U[i] - sum(prod(π[j,a[j]] for j in ℐ) * R[y][i]\n",
    "       for (y,a) in enumerate(joint(𝒜))) for i in ℐ))\n",
    "   @NLconstraint(model, [i=ℐ, ai=𝒜[i]],U[i] ≥ sum(\n",
    "       prod(j==i ? (a[j]==ai ? 1.0 : 0.0) : π[j,a[j]] for j in ℐ)\n",
    "       * R[y][i] for (y,a) in enumerate(joint(𝒜))))\n",
    "   @constraint(model, [i=ℐ], sum(π[i,ai] for ai in 𝒜[i]) == 1)\n",
    "   optimize!(model)\n",
    "   πi′(i) = SimpleGamePolicy(𝒫.𝒜[i][ai] => value(π[i,ai]) for ai in 𝒜[i])\n",
    "   return [πi′(i) for i in ℐ]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorform (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function tensorform(𝒫::SimpleGame)\n",
    "   ℐ, 𝒜, R = 𝒫.ℐ, 𝒫.𝒜, 𝒫.R\n",
    "   ℐ′ = eachindex(ℐ)\n",
    "   𝒜′ = [eachindex(𝒜[i]) for i in ℐ]\n",
    "   R′ = [R(a) for a in joint(𝒜)]\n",
    "   return ℐ′, 𝒜′, R′\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthOfPlan = 2\n",
    "beliefInit = [0.5, 0.5]\n",
    "function POMGNashEquilibrium_Init()\n",
    "    return POMGNashEquilibrium(\n",
    "        beliefInit,\n",
    "        depthOfPlan\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function solve(M::POMGNashEquilibrium, 𝒫::POMG)\n",
    "   ℐ, γ, b, d = 𝒫.ℐ, 𝒫.γ, M.b, M.d\n",
    "   Π = create_conditional_plans(𝒫, d)\n",
    "   U = Dict(π => utility(𝒫, b, π) for π in joint(Π))\n",
    "   𝒢 = SimpleGame(γ, ℐ, Π, π -> U[π])\n",
    "   π = solve(NashEquilibrium(), 𝒢)\n",
    "   return Tuple(argmax(πi.p) for πi in π)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPOMG = POMG_Init()\n",
    "myNash = POMGNashEquilibrium_Init()\n",
    "result = solve(myNash, myPOMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37eb40c3388cfde35488e2d005b0d69ca91ddeff8a429754d4da636d3f888e5e"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
