{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using GLPK\n",
    "using XLSX\n",
    "using Ipopt\n",
    "using D3Trees\n",
    "using BenchmarkTools\n",
    "import Base.Iterators: product\n",
    "import Random.shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ordered_observations (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SATED = 1\n",
    "HUNGRY = 2\n",
    "FEED = 1\n",
    "IGNORE = 2\n",
    "SING = 3\n",
    "CRYING = true\n",
    "QUIET = false\n",
    "r_hungry = -10.0\n",
    "r_feed = -5.0\n",
    "r_sing = -0.5\n",
    "p_become_hungry = 0.1\n",
    "p_cry_when_hungry = 0.8\n",
    "p_cry_when_not_hungry = 0.1\n",
    "p_cry_when_hungry_in_sing = 0.9\n",
    "discount_factor = 0.9\n",
    "n_agents = 2\n",
    "ordered_states() = [SATED, HUNGRY]\n",
    "ordered_actions(i::Int) = [FEED, IGNORE, SING]\n",
    "ordered_observations(i::Int) = [CRYING, QUIET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct POMG\n",
    "   Œ≥ # discount factor\n",
    "   ‚Ñê # agents\n",
    "   ùíÆ # state space\n",
    "   ùíú # joint action space\n",
    "   ùí™ # joint observation space\n",
    "   T # transition function\n",
    "   O # joint observation function\n",
    "   R # joint reward function\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SimpleGame\n",
    "   Œ≥ # discount factor\n",
    "   ‚Ñê # agents\n",
    "   ùíú # joint action space\n",
    "   R # joint reward function\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct NashEquilibrium \n",
    "end\n",
    "\n",
    "struct ConditionalPlan\n",
    "   a # action to take at root\n",
    "   subplans # dictionary mapping observations to subplans\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct POMGNashEquilibrium\n",
    "   b # initial belief\n",
    "   d # depth of conditional plans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transition (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function transition(s, a, s1)\n",
    "   # Regardless, feeding makes the baby sated.\n",
    "   if a[1] == FEED || a[2] == FEED\n",
    "       if s1 == SATED\n",
    "           return 1.0\n",
    "       else\n",
    "           return 0.0\n",
    "       end\n",
    "   else\n",
    "       # If neither caretaker fed, then one of two things happens.\n",
    "       # First, a baby that is hungry remains hungry.\n",
    "       if s == HUNGRY\n",
    "           if s1 == HUNGRY\n",
    "               return 1.0\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Otherwise, it becomes hungry with a fixed probability.\n",
    "       else\n",
    "           probBecomeHungry = 0.5 #pomg.babyPOMDP.p_become_hungry\n",
    "           if s1 == SATED\n",
    "               return 1.0 - probBecomeHungry\n",
    "           else\n",
    "               return probBecomeHungry\n",
    "           end\n",
    "       end\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_reward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function joint_reward(s, a)\n",
    "   r = [0.0, 0.0]\n",
    "\n",
    "   # Both caregivers do not want the child to be hungry.\n",
    "   if s == HUNGRY\n",
    "       r += [r_hungry, r_hungry]\n",
    "   end\n",
    "\n",
    "   # One caregiver prefers to feed.\n",
    "   if a[1] == FEED\n",
    "       r[1] += r_feed / 2.0\n",
    "   elseif a[1] == SING\n",
    "       r[1] += r_sing\n",
    "   end\n",
    "\n",
    "   # One caregiver prefers to sing.\n",
    "   if a[2] == FEED\n",
    "       r[2] += r_feed\n",
    "   elseif a[2] == SING\n",
    "       r[2] += r_sing / 2.0\n",
    "   end\n",
    "\n",
    "   # Note that caregivers only experience a cost if they do something.\n",
    "\n",
    "   return r\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Observation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint_observation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function joint_observation(a, s1, o)\n",
    "   # If at least one caregiver sings, then both observe the result.\n",
    "   if a[1] == SING || a[2] == SING\n",
    "       # If the baby is hungry, then the caregivers both observe crying/silent together.\n",
    "       if s1 == HUNGRY\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_hungry_in_sing\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_hungry_in_sing\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Otherwise the baby is sated, and the baby is silent.\n",
    "       else\n",
    "           if o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       end\n",
    "   # Otherwise, the caregivers fed and/or ignored the baby.\n",
    "   else\n",
    "       # If the baby is hungry, then there's a probability it cries.\n",
    "       if s1 == HUNGRY\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_hungry\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_hungry\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       # Similarly when it is sated.\n",
    "       else\n",
    "           if o[1] == CRYING && o[2] == CRYING\n",
    "               return p_cry_when_not_hungry\n",
    "           elseif o[1] == QUIET && o[2] == QUIET\n",
    "               return 1.0 - p_cry_when_not_hungry\n",
    "           else\n",
    "               return 0.0\n",
    "           end\n",
    "       end\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize POMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POMG_Init (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function POMG_Init()\n",
    "   return POMG(\n",
    "       discount_factor,\n",
    "       vec(collect(1:n_agents)),\n",
    "       ordered_states(),\n",
    "       [ordered_actions(i) for i in 1:n_agents],\n",
    "       [ordered_observations(i) for i in 1:n_agents],\n",
    "       (s, a, s1) -> transition(s, a, s1),\n",
    "       (a, s1, o) -> joint_observation(a, s1, o),\n",
    "       (s, a) -> joint_reward(s, a)\n",
    "   )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Conditioinal Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConditionalPlan(a) = ConditionalPlan(a, Dict())\n",
    "(œÄ::ConditionalPlan)() = œÄ.a\n",
    "(œÄ::ConditionalPlan)(o) = œÄ.subplans[o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ConditionalPlan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lookahead (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function lookahead(ùí´::POMG, U, s, a)\n",
    "   ùíÆ, ùí™, T, O, R, Œ≥ = ùí´.ùíÆ, joint(ùí´.ùí™), ùí´.T, ùí´.O, ùí´.R, ùí´.Œ≥\n",
    "   u‚Ä≤ = sum(T(s,a,s‚Ä≤)*sum(O(a,s‚Ä≤,o)*U(o,s‚Ä≤) for o in ùí™) for s‚Ä≤ in ùíÆ)\n",
    "   return R(s,a) + Œ≥*u‚Ä≤\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_plan (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function evaluate_plan(ùí´::POMG, œÄ, s)\n",
    "   a = Tuple(œÄi() for œÄi in œÄ)\n",
    "   U(o,s‚Ä≤) = evaluate_plan(ùí´, [œÄi(oi) for (œÄi, oi) in zip(œÄ,o)], s‚Ä≤)\n",
    "   return isempty(first(œÄ).subplans) ? ùí´.R(s,a) : lookahead(ùí´, U, s, a)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utility (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function utility(ùí´::POMG, b, œÄ)\n",
    "   u = [evaluate_plan(ùí´, œÄ, s) for s in ùí´.ùíÆ]\n",
    "   return sum(bs * us for (bs, us) in zip(b, u))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_conditional_plans (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function create_conditional_plans(ùí´, d)\n",
    "   ‚Ñê, ùíú, ùí™ = ùí´.‚Ñê, ùí´.ùíú, ùí´.ùí™\n",
    "   Œ† = [[ConditionalPlan(ai) for ai in ùíú[i]] for i in ‚Ñê]\n",
    "   for t in 1:d\n",
    "      Œ† = expand_conditional_plans(ùí´, Œ†)\n",
    "   end\n",
    "   return Œ†\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expand_conditional_plans (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function expand_conditional_plans(ùí´, Œ†)\n",
    "   ‚Ñê, ùíú, ùí™ = ùí´.‚Ñê, ùí´.ùíú, ùí´.ùí™\n",
    "   return [[ConditionalPlan(ai, Dict(oi => œÄi for oi in ùí™[i])) for œÄi in Œ†[i] for ai in ùíú[i]] for i in ‚Ñê]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SimpleGamePolicy\n",
    "   p # dictionary mapping actions to probabilities\n",
    "   function SimpleGamePolicy(p::Base.Generator)\n",
    "       return SimpleGamePolicy(Dict(p))\n",
    "   end\n",
    "\n",
    "   function SimpleGamePolicy(p::Dict)\n",
    "       vs = collect(values(p))\n",
    "       vs ./= sum(vs)\n",
    "       return new(Dict(k => v for (k,v) in zip(keys(p), vs)))\n",
    "   end\n",
    "   SimpleGamePolicy(ai) = new(Dict(ai => 1.0))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(œÄi::SimpleGamePolicy)(ai) = get(œÄi.p, ai, 0.0)\n",
    "function (œÄi::SimpleGamePolicy)()\n",
    "   D = SetCategorical(collect(keys(œÄi.p)), collect(values(œÄi.p)))\n",
    "   return rand(D)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joint (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joint(X) = vec(collect(product(X...)))\n",
    "joint(œÄ, œÄi, i) = [i == j ? œÄi : œÄj for (j, œÄj) in enumerate(œÄ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utility (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function utility(ùí´::SimpleGame, œÄ, i)\n",
    "   ùíú, R = ùí´.ùíú, ùí´.R\n",
    "   p(a) = prod(œÄj(aj) for (œÄj, aj) in zip(œÄ, a))\n",
    "   return sum(R(a)[i]*p(a) for a in joint(ùíú))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function solve(M::NashEquilibrium, ùí´::SimpleGame)\n",
    "   ‚Ñê, ùíú, R = tensorform(ùí´)\n",
    "   model = Model(Ipopt.Optimizer)\n",
    "   @variable(model, U[‚Ñê])\n",
    "   @variable(model, œÄ[i=‚Ñê, ùíú[i]] ‚â• 0)\n",
    "   @NLobjective(model, Min,\n",
    "       sum(U[i] - sum(prod(œÄ[j,a[j]] for j in ‚Ñê) * R[y][i]\n",
    "       for (y,a) in enumerate(joint(ùíú))) for i in ‚Ñê))\n",
    "   @NLconstraint(model, [i=‚Ñê, ai=ùíú[i]],U[i] ‚â• sum(\n",
    "       prod(j==i ? (a[j]==ai ? 1.0 : 0.0) : œÄ[j,a[j]] for j in ‚Ñê)\n",
    "       * R[y][i] for (y,a) in enumerate(joint(ùíú))))\n",
    "   @constraint(model, [i=‚Ñê], sum(œÄ[i,ai] for ai in ùíú[i]) == 1)\n",
    "   optimize!(model)\n",
    "   œÄi‚Ä≤(i) = SimpleGamePolicy(ùí´.ùíú[i][ai] => value(œÄ[i,ai]) for ai in ùíú[i])\n",
    "   return [œÄi‚Ä≤(i) for i in ‚Ñê]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorform (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function tensorform(ùí´::SimpleGame)\n",
    "   ‚Ñê, ùíú, R = ùí´.‚Ñê, ùí´.ùíú, ùí´.R\n",
    "   ‚Ñê‚Ä≤ = eachindex(‚Ñê)\n",
    "   ùíú‚Ä≤ = [eachindex(ùíú[i]) for i in ‚Ñê]\n",
    "   R‚Ä≤ = [R(a) for a in joint(ùíú)]\n",
    "   return ‚Ñê‚Ä≤, ùíú‚Ä≤, R‚Ä≤\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthOfPlan = 2\n",
    "beliefInit = [0.5, 0.5]\n",
    "function POMGNashEquilibrium_Init()\n",
    "    return POMGNashEquilibrium(\n",
    "        beliefInit,\n",
    "        depthOfPlan\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function solve(M::POMGNashEquilibrium, ùí´::POMG)\n",
    "   ‚Ñê, Œ≥, b, d = ùí´.‚Ñê, ùí´.Œ≥, M.b, M.d\n",
    "   Œ† = create_conditional_plans(ùí´, d)\n",
    "   U = Dict(œÄ => utility(ùí´, b, œÄ) for œÄ in joint(Œ†))\n",
    "   ùí¢ = SimpleGame(Œ≥, ‚Ñê, Œ†, œÄ -> U[œÄ])\n",
    "   œÄ = solve(NashEquilibrium(), ùí¢)\n",
    "   return Tuple(argmax(œÄi.p) for œÄi in œÄ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPOMG = POMG_Init()\n",
    "myNash = POMGNashEquilibrium_Init()\n",
    "result = solve(myNash, myPOMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37eb40c3388cfde35488e2d005b0d69ca91ddeff8a429754d4da636d3f888e5e"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
